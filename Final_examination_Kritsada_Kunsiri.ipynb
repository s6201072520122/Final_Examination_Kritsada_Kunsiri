{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python==4.5.3.56 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.5.3.56)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opencv-contrib-python==4.5.3.56) (1.21.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install  opencv-contrib-python==4.5.3.56\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import scipy\n",
    "import matplotlib.pylab as plt\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_compare(img1, img2) :\n",
    "    fig, axes = plt.subplots(1,2, figsize = (20,20))\n",
    "    axes[0].imshow(img1)\n",
    "    axes[1].imshow(img2)\n",
    "\n",
    "def preprocessing(img) :\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return (img, img_gray) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# นำภาพ Template และ ภาพ ArUco เข้ามา\n",
    "# เก็บภาพ QRcode ไว้ใน QRC ขนาดเท่าหนังสือ 182*240 mm. หรือ 469*347 px แต่ ArUco ใช้ 150 mm.\n",
    "QRC = cv2.imread('./images/QRCode2.png')\n",
    "\n",
    "# เก็บภาพ หนังสือต้นแบบ ไว้ใน template 182*240 mm. หรือ 469*347 px\n",
    "template = cv2.imread('./images/Template-3.png')\n",
    "templatecopy = template.copy()\n",
    "\n",
    "# แปลงจาก BGR เป็น RGB\n",
    "template_img = cv2.cvtColor(template, cv2.COLOR_BGR2RGB)\n",
    "templatecopy = cv2.cvtColor(templatecopy, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# #แสดงผล\n",
    "# imshow_compare(QRC, templatecopy)\n",
    "# print(QRC.shape) #ปริ้นดูขนาด\n",
    "# print(template_img.shape) #ปริ้นดูขนาด"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### สร้างฟังก์ชั่น AruCo_Warp_and_stitch เพื่อนำ QRcode ไปแปะที่หนังสือในวิดีโอ\n",
    "def AruCo_Warp_and_stitch(video_2, QRC, H) : # Warp and stitch\n",
    "    rows, cols = video_2.shape[:2]\n",
    "    warped_img = cv2.warpPerspective(QRC, H, (2*cols, 2*rows))\n",
    "    enlarge_ref_img = np.zeros((2*rows, 2*cols, 3), dtype=np.uint8)\n",
    "    enlarge_ref_img[:rows, :cols] = video_2\n",
    "    warped_gray = cv2.cvtColor(warped_img, cv2.COLOR_RGB2GRAY)\n",
    "    warped_mask = cv2.threshold(warped_gray, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "    segmented_ref_img = cv2.add(warped_img, enlarge_ref_img, mask=np.bitwise_not(warped_mask))\n",
    "    result = cv2.add(segmented_ref_img, warped_img)\n",
    "\n",
    "    grayscale = cv2.cvtColor(result, cv2.COLOR_RGB2GRAY)\n",
    "    mask = cv2.threshold(grayscale, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "    # ค้นหาคอนทัวร์ภายในมาส์ก \n",
    "    contour, hier = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # รับคอนทัวร์ด้วยพื้นที่สูงสุด\n",
    "    max_area_contour = max(contour, key=cv2.contourArea)\n",
    "\n",
    "    # สร้างขอบกล่อง\n",
    "    (x, y, w, h) = cv2.boundingRect(max_area_contour)\n",
    "    \n",
    "    # return กลับ\n",
    "    return result[:h, :w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\Final_examination_Kritsada_Kunsiri\\Final_Examination_Kritsada_Kunsiri/new-camera_params_Final_examination/\n",
      "Camera matrix\n",
      "[[726.47630281   0.         466.2575863 ]\n",
      " [  0.         732.06406134 251.99786765]\n",
      " [  0.           0.           1.        ]]\n",
      "Len distortion\n",
      "[[ 0.02450981  0.03012141  0.00045661  0.01036187 -0.07354295]]\n"
     ]
    }
   ],
   "source": [
    "######### ใช้ในขั้นตอนที่ 3 หาตำเหน่ง (X,Y,Z)\n",
    "# โหลดค่า camera_params Calibration มาใช้\n",
    "params_dir = os.getcwd()+'/new-camera_params_Final_examination/'\n",
    "print(params_dir)\n",
    "\n",
    "# ใช้ค่า K กับ ค่า dist\n",
    "K = np.load(params_dir+'K.npy')\n",
    "dist = np.load(params_dir+'dist.npy')\n",
    "\n",
    "print(\"Camera matrix\")\n",
    "print(K)\n",
    "print(\"Len distortion\")\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## กำหนดใช้ในขั้นตอนที่ 3 หาตำเหน่ง (X,Y,Z)\n",
    "# นำเข้า arucoDictionary\n",
    "AruCo_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n",
    "AruCo_params = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "# (xกี่ตัว , กี่ตัว , ความยาวแต่ละด้าน , ,) ในกรณีนี้ใช้แค่ 1 ตัว ความยาวแต่ละด้านเท่าหนังสือ\n",
    "board = cv2.aruco.GridBoard_create(1, 1, 0.150, 0.1, AruCo_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## กำหนดใช้ในขั้นตอนที่ 3 ใช้แสดงตำเหน่ง (X,Y,Z)\n",
    "def write_text_position(detected_video, pose, dy, text) :\n",
    "    x0 = pose[0]\n",
    "    y0 = pose[1]\n",
    "    for i, line in enumerate(text.split('\\n')) :\n",
    "        y = y0 + i*dy\n",
    "                                                             #( เปลี่ยน ฟร้อน, สี, ขนาด ตัวหนังสือ )\n",
    "        cv2.putText(detected_video, line, np.int32([x0, y]), cv2.FONT_HERSHEY_COMPLEX, 0.6, (0,255,0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_matching_and_position_detection(video_device) :\n",
    "    \n",
    "    video = cv2.VideoCapture(video_device)\n",
    "    video.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    video.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "    ret, old_frame = video.read()\n",
    "    # print(old_frame.shape)\n",
    "    # old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    template = cv2.imread('./images/Template-3.png')\n",
    "    template_img = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    # print(template.shape)\n",
    "    template2 = template.copy()\n",
    "    kernel = np.array([[0,-1,0],\n",
    "                     [-1,8,-1],\n",
    "                     [0,-1,0]],dtype=np.float32)\n",
    "    template2 = cv2.filter2D(template2,-3,kernel)\n",
    "    \n",
    "    # วิดีโอเปิด\n",
    "    while video.isOpened() : \n",
    "        ret, video_1 = video.read()\n",
    "        ret, video_2 = video.read()\n",
    "        \n",
    "        # True\n",
    "        if ret :\n",
    "            \n",
    "            query_video = video_1\n",
    "            query_gray_video = cv2.cvtColor(video_1, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # วิดีโอมีความละเอียดไม่มากทำให้การตรวจจับเกิดการผิดพลาดดังนั้นจึงทำการ ทำให้ภาพคมชัดขึ้น\n",
    "            kernel = np.array([[0,0,0],\n",
    "                   [0,1.7,0],\n",
    "                   [0,0,0]],dtype=np.float32)\n",
    "            query_gray_video = cv2.filter2D(query_gray_video,-3,kernel)\n",
    "            \n",
    "        ######################################################### ขั้นตอนที่ 1 ใช้ SIFT ตรวจจับหนังสือในวิดีโอ\n",
    "            \n",
    "            # กำหนด SIFT\n",
    "            sift = cv2.SIFT_create() \n",
    "\n",
    "            # ใช้ BFMatcher ในการจับคู่ภาพ\n",
    "            bf = cv2.BFMatcher()\n",
    "\n",
    "            # จะเรียกใช้มัน คำสั่ง sift.detectAndCompute\n",
    "            template_kpts, template_desc = sift.detectAndCompute(template_img, None)\n",
    "            query_kpts, query_desc = sift.detectAndCompute(query_gray_video, None)\n",
    "\n",
    "            # เอาพอยที่หาจากภาพและวิดีโอมา matc กัน\n",
    "            matches = bf.knnMatch(template_desc, query_desc, k=2)\n",
    "\n",
    "            # ได้ค่า good_matches เพื่อนำไป RANSAC \n",
    "            good_matches = list()\n",
    "            good_matches_list = list()\n",
    "            \n",
    "            # หาคู่ที่โดดเด่น\n",
    "            for m, n in matches :\n",
    "                if m.distance < 0.57*n.distance :\n",
    "                    good_matches.append(m)           \n",
    "                    good_matches_list.append([m])\n",
    "         \n",
    "        ########################################################## ขั้นตอนที่ 2 ใช้ RANSAC หาคู่ matc ที่ดีที่สุดเพื่อความแม่นยำในการตรวจจับ\n",
    "            \n",
    "            # ตั้งเงื่อนไข good_matches น้อยกว่า 12\n",
    "            if len(good_matches) > 12 :\n",
    "                src_pts = np.float32([ template_kpts[m.queryIdx].pt for m in good_matches ]).reshape(-1,1,2)\n",
    "                dst_pts = np.float32([ query_kpts[m.trainIdx].pt for m in good_matches ]).reshape(-1,1,2)\n",
    "\n",
    "                H, inlier_masks = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 0.95) # H RANSAC\n",
    "\n",
    "                # รับกรอบล้อมรอบภาพเทมเพลต สีแดง \n",
    "                h, w = template_img.shape[:2]\n",
    "\n",
    "                # วาด กล่องสีแดงครอบหนังสือที่จับเจอ\n",
    "                template_box = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1,1,2) \n",
    "                transformed_box = cv2.perspectiveTransform(template_box, H)\n",
    "                \n",
    "                # นำตัวVDO detected_video ไปใช้ต่อในการจับหาตำแหน่ง (X,Y,Z)\n",
    "                detected_video = cv2.polylines(query_video, [np.int32(transformed_box)], True, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "                # drawmatch_img แสดงการจับกันของคู่แมทต์ ลากเส้นหากัน \n",
    "                #drawmatch_img = cv2.drawMatchesKnn(template_img, template_kpts, detected_video, query_kpts, good_matches_list, None, flags=2, matchesMask=inlier_masks)\n",
    "\n",
    "                # เรียกใช้ฟังก์ชั้น AruCo_Warp_and_stitch จะวาปภาพ QRC เข้าไปทับหนังสือในวิดีโอ video_2 ใช้เพื่อหาตำแหน่ง (X,Y,Z)\n",
    "                result = AruCo_Warp_and_stitch(video_2, QRC, H) \n",
    "\n",
    "                # copy วิดีโอ result เก็บไว้ใน result2 นำไปใช้ขั้นตอนต่อไป\n",
    "                result2 = result.copy()\n",
    "            \n",
    "        ########################################################## ขั้นตอนที่ 3 ใช้ ArUco หาตำเหน่ง (X,Y,Z) ของหนังสือในวิดีโอ\n",
    "            \n",
    "            # ใช้ cv2.aruco.detectMarkers โยน วิดีโอเข้าไป , AruCo_dict , parameters\n",
    "            # ได้มุม , id\n",
    "            markerCorners, markerIds, rejectedCandidates = cv2.aruco.detectMarkers(result, AruCo_dict, parameters = AruCo_params)\n",
    "            \n",
    "            # ถ้า markerCorners มากกว่า 0 คือถ้าเจอ aruco\n",
    "            if len(markerCorners) > 0:\n",
    "\n",
    "                # cv2.aruco.drawDetectedMarkers วาด ตัว Markers ลงไปในวิดีโอ\n",
    "                result2 = cv2.aruco.drawDetectedMarkers(result, markerCorners)\n",
    "                \n",
    "                # cv2.aruco.estimatePoseSingleMarkers ได้ rvecs มุมการหมุน ,  tvecs ตำแหน่ง , points จุดที่เจอ\n",
    "                rvecs, tvecs, points = cv2.aruco.estimatePoseSingleMarkers(markerCorners , 0.150, K, dist) # 0.182 ขนาด aruco บนหนังสือ\n",
    "                for (rvec, tvec, id, corner) in zip(rvecs, tvecs, markerIds, markerCorners) :\n",
    "                    #detected_img = cv2.aruco.drawAxis(detected_img, K, dist, rvec, tvec, 0.182)\n",
    "                    x = tvec[0,0]\n",
    "                    y = tvec[0,1]\n",
    "                    z = tvec[0,2]\n",
    "                    text = \"pose: X:{:.1f} Y:{:.1f} Z:{:.1f}\".format(x, y, z)\n",
    "                    cX = (corner[0,0][0] + corner[0,2][0]) / 2\n",
    "                    cY = (corner[0,0][1] + corner[0,2][1]) / 2\n",
    "                    write_text_position(detected_video, (cX, cY), 20, text)\n",
    "                ret, brvec, btvec = cv2.aruco.estimatePoseBoard(markerCorners, markerIds, board, K, dist, rvecs, tvecs) \n",
    "                if ret :\n",
    "                    result2 = cv2.aruco.drawAxis(result, K, dist, brvec, btvec, 0.05)\n",
    "           \n",
    "                    \n",
    "            #cv2.imshow('Video frame', result2 ) # ดู aruco ที่ถูกติดกับหนังสือในวิดีโอ\n",
    "            #cv2.imshow('Video frame', drawmatch_img) # ดู matching\n",
    "\n",
    "            cv2.imshow('Video frame', detected_video)\n",
    "\n",
    "            # ถ้ากด q ทำการปิดวิดีโอที่เล่นอยู่\n",
    "            if cv2.waitKey(int(1000/24)) & 0xFF == ord('q') :\n",
    "                break\n",
    "        else :\n",
    "            break\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "feature_matching_and_position_detection('./videos/final_exam/Dataset-1/left_output-1.avi') # ใช้วิดีโอจากมุมกล้องซ้าย"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcacb0086e9a4f4eabd41c33bf4faac5ea0a3337ed3f5eff0680afa930572c04"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
